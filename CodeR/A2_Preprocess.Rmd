---
title:  "A2_Preprocess.Rmd / Heat-Related Mortality / Exposure Response"
author: "Hans-Aloys Wischmann, Institute for Public Health, Charité - Universitätsmedizin Berlin"
date:   "Written: 2023-04-12 to 2023-08-31 / Totally revised: 2024-11-07 to 2025-07-04 / Executed: `r Sys.Date()`"
output:
  officedown::rdocx_document:
    reference_docx: A4_Template.docx
    tables:
      style: Normal
    plots:
      style: Normal
---

```{r setup, include = FALSE}
  source("./A1_Parameters.R")
  library_wrapper(c("lubridate", "readxl", "ncdf4", "ggh4x"))

  # configurable parameters: countries and NUTS levels to process, geographies to exclude (regular expressions)
  countries_of_interest  <- c("UK" = "United Kingdom", "FR" = "France", "DE" = "Germany", "IT" = "Italy", "ES" = "Spain",
                              "PT" = "Portugal", "BE" = "Belgium", "NL" = "Netherlands", "CH" = "Switzerland", "AT" = "Austria")
  levels_of_interest     <- c("UK" = 1, "FR" = 2, "DE" = 1, "IT" = 2, "ES" = 2, "PT" = 2, "BE" = 2, "NL" = 2, "CH" = 2, "AT" = 2)
  geographies_to_exclude <- "^FRY|^FRX|^ES7|^ES63|^ES64|^UKN|^UKM|^PT2|^PT3"

  # read/write csv and tsv files in "UTF-8" encoding with semi-colon as separator, without row numbers
  load_csv <- function(file) { return(read.csv(file, sep = ";",  encoding = "UTF-8")) }
  load_tsv <- function(file) { return(read.csv(file, sep = "\t", encoding = "UTF-8")) }
```
# Prerequisites and Expected Execution Time

Prerequisites: A0_Download.sh successfully completed, A1_Parameters.R reviewed and confirmed

Expected execution time: About 4 minutes (12/24 physical/logical cores @ 5.7 GHz, 32 GB RAM)

# Geography

Acknowledgement for administrative boundaries: © EuroGeographics for the administrative boundaries.

Populations are only available separately for England and Wales, so that they need to be treated as separate countries for the pre-processing.

```{r NUTS}
  # read NUTS map / geography provided by EU commission, note required acknowledgement (above)
  geo_info <- data.frame(read_sf("../Downloads/Geography/NUTS_RG_01M_2021_4326.shp")) %>%
    filter(LEVL_CODE %in% 1:2, str_sub(NUTS_ID, 1, 2) %in% names(countries_of_interest)) %>%             # 1st to 2nd level
    select(level = LEVL_CODE, id_region = NUTS_ID, region = NUTS_NAME, geometry) %>%                     # discard irrelevant info
    mutate(region = ifelse(str_sub(region, 1, 6) != "Centre", region, "Centre-Val de Loire")) %>%        # fix nasty hyphen
    mutate(region = ifelse(str_sub(region, 1, 6) != "Proven", region, "Provence-Alpes-Côte d'Azur")) %>% # fix nasty apostrophe
    mutate(country = str_replace_all(str_sub(id_region, 1, 2), countries_of_interest)) %>%               # assign country to each geo
    mutate(country = ifelse(str_sub(id_region, 1, 2) == "UK",  "England", country)) %>%                  # treat England as a country
    mutate(country = ifelse(str_sub(id_region, 1, 3) == "UKL", "Wales",   country)) %>%                  # treat Wales as a country
    arrange(country, region) %>%
    filter(level == levels_of_interest[str_sub(id_region, 1, 2)])
  geo_info %>% select(NUTS = id_region, Region = region) %>%
    filter(grepl(geographies_to_exclude, NUTS)) %>%
    arrange(NUTS) %>%
    flextable() %>% set_caption("Excluded Regions") %>% autofit()
  geo_info <- geo_info %>% filter(!grepl(geographies_to_exclude, id_region)) 
  save(geo_info, file = "../Processed/Geography.Rdata", compress = "xz")

  # process 5-digit post / zip codes for France, for mapping individual death record locations to NUTS3 regions
  zip_codes_fr <- load_csv("../Downloads/Geography/pc2020_FR_NUTS-2021_v2.0.csv") %>%
    mutate(id_region = str_replace_all(NUTS3, "'", ""), zip = as.integer(str_replace_all(CODE, "'", "")) %/% 1000) %>%
    group_by(id_region) %>% reframe(zip = median(zip)) %>% arrange(zip) %>% filter(zip <= 95) %>% # metropolitan France only
    mutate(id_region = str_sub(id_region, 1, 2 + levels_of_interest["FR"])) %>%
    left_join(., geo_info, by = "id_region") %>%
    select(zip, id_region) %>%
    mutate(zip = case_when(id_region == "FRM01" ~ "2A", id_region == "FRM02" ~ "2B", TRUE ~ as.character(zip))) %>%
    distinct()

  # number of regions per country
  geo_info %>% select(id_region, Country = country) %>%
    mutate(Country = ifelse(Country %in% c("England", "Wales"), "England.Wales", Country)) %>%
    group_by(Country) %>% reframe(n = n()) %>%
    bind_rows(reframe(., Country = paste("Total, N=", n(), sep = ""), n = sum(n))) %>%
    flextable() %>% set_caption("Number of Regions per Country") %>% hline(i = 10) %>% autofit()
```
# Populations: Eurostat

© European Union, 1995-2024

Unless otherwise indicated (e.g. in individual copyright notices), content owned by the EU on this website is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) licence. This means that reuse is allowed, provided appropriate credit is given and changes are indicated

```{r population_eurostat}
  # string to convert age range texts to age ranges
  ages_replace <- c("Y_LT1" = "0", "Y_LT5" = "0-4", "Y_GE85" = "85-99", "Y" = "")
  ages_ignore  <- c("UNK", "TOTAL", "Y_GE75", "Y_GE80", "Y_GE90", "Y_OPEN")

  # read NUTS2 level populations statistics file from Eurostat
  population_eurostat <- load_tsv("../Downloads/Population/Population_NUTS2.tsv") %>%
    rename("label" = "freq.unit.sex.age.geo.TIME_PERIOD") %>%
    separate_wider_delim(label, names = c("ignore1", "ignore2", "sex", "age", "geo"), delim = ",") %>%
    filter(sex %in% c("F", "M"), !age %in% ages_ignore, geo %in% unique(geo_info$id_region), str_sub(geo, 1, 2) != "UK") %>%
    mutate(country = as.character(countries_of_interest[str_sub(geo, 1, 2)])) %>%
    select(geo, country, sex, age, starts_with("X20")) %>%
    pivot_longer(starts_with("X"), names_to = "year", values_to = "n_pop") %>%
    mutate(age = str_replace_all(age, ages_replace)) %>%
    filter(!grepl(":", n_pop)) %>%
    mutate(year = as.double(str_sub(year, 2, -1)), n_pop = as.integer(gsub(" .*$", "", n_pop)))

  # manually correct missing/broken entry that could be recovered/computed for Male from Total - Female
  population_eurostat <-
    rbind(population_eurostat, data.frame(geo = "ES21", country = "Spain", sex = "M", age = "45-49", year = 2001, n_pop = 71911))
  population_eurostat %>% filter(geo == "ES21", year == 2001, age == "45-49") %>%
    select(Region = geo, Country = country, Sex = sex, Age = age, Year = year, n_pop) %>%
    flextable() %>% set_caption("Missing n_pop Data for Males from Total - Females")
```
# Populations: ONS

ONS Crown Copyright Reserved [from Nomis on 25 June 2024]

```{r population_ONS}
  # read NOMIS query results files, excluding Scotland and Northern Ireland
  population_region_ONS <- load_tsv("../Downloads/Population/Population_England_Wales_NUTS1.tsv") %>%
    filter(!region %in% c("Scotland", "Northern Ireland")) %>%
    mutate(sex = str_sub(Gender, 1, 1), age = str_replace_all(Age, c("Age " = "", "Aged " = "", " " = "", "85[+]" = "85-99"))) %>%
    left_join(., geo_info %>% select(id_region, region) %>%
    mutate(region = str_replace_all(region, c(" [(]England[)]" = "", " of England" = "", "the" = "The"))), by = "region") %>%
    mutate(country = ifelse(region == "Wales", "Wales", "England")) %>%
    select(geo = id_region, country, sex, age, year = date, n_pop = value)
```
# Populations: Aggregate and Visualize

```{r populations}
  # combine Eurostat and ONS populations data, by 5 year groups, and aggregate to 4 coarse brackets
  population_5y   <- rbind(population_eurostat, population_region_ONS)
  population_4cat <- left_join(population_5y, age_aggregate, by = "age") %>%
    group_by(geo, country, sex, year, age = age_cat) %>% reframe(n_pop = sum(n_pop))

  # clean up
  print(sprintf("Populations.Rdata (is.na = %d)", sum(is.na(population_5y)) + sum(is.na(population_4cat))))
  rm(list = setdiff(ls(pattern = "population"), c("population_4cat", "population_5y"))); stop_gc()

  # quick visual inspection
  plot_pdf_png("Figure_X1", aspect_ratio = 1.0,
    population_5y %>% filter(year == 2022) %>% mutate(n_pop = ifelse(sex == "F", -n_pop, n_pop)) %>%
    left_join(., age_5y_standard, by = "age") %>% arrange(age_from) %>% mutate(age = fct_inorder(age)) %>%
    ggplot(aes(x = age, y = n_pop, fill = sex)) + geom_col() +
      scale_y_continuous(labels = ~abs(.x)) +
      scale_fill_discrete(name = "Sex") +
      labs(x = "Age [years]", y = "") + coord_flip() + 
      facet_wrap(~country, scales = "free_x") +
      std_theme() + theme(legend.position = "bottom"))
  print("Figure_X1: Population Data 2022, © European Union, 1995-2024 and ONS, 2024")
```
# Deaths (Eurostat)

© European Union, 1995-2024

Unless otherwise indicated (e.g. in individual copyright notices), content owned by the EU on this website is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) licence. This means that reuse is allowed, provided appropriate credit is given and changes are indicated

```{r deaths_eurostat}
  # string to convert age range texts to age ranges
  ages_replace <- c("Y_LT1" = "0", "Y_LT5" = "0-4", "Y_GE85" = "85-99", "Y_GE90" = "90-99", "Y" = "")
  ages_ignore  <- c("UNK", "TOTAL")

  # read NUTS2 level weekly death statistics file from Eurostat
  deaths_eurostat <- load_tsv("../Downloads/Population/Deaths_Weekly_NUTS2.tsv")  %>% 
    # separate concatenated variables from label column
    rename("label" = "freq.age.sex.unit.geo.TIME_PERIOD") %>%
    separate_wider_delim(label, names = c("ignore1", "age", "sex", "ignore2", "geo"), delim = ",") %>%
    # use data by sex, ignore deaths at unknown age, select only geographies of interest
    filter(sex %in% c("F", "M"), !age %in% ages_ignore, geo %in% unique(geo_info$id_region), !str_sub(geo, 1, 2) %in% c("UK", "FR", "DE")) %>%
    mutate(age = str_replace_all(age, ages_replace)) %>%
    # keep only relevant info, in correct order
    select(geo, sex, age, starts_with("X20")) %>%
    # convert to tidy format
    pivot_longer(starts_with("X"), names_to = "year_week", values_to = "n_deaths") %>%
    # convert year.week into start date of week
    mutate(year_week = str_replace_all(year_week, c("X" = "", "[.]" = "-", "$" = "-1")), date_from = ISOweek2date(year_week)) %>%
    # remove rows with missing data and convert number of deaths to integer
    filter(!grepl(":", n_deaths)) %>% mutate(n_deaths = as.integer(gsub(" .*$", "", n_deaths))) %>%
    mutate(country = as.character(countries_of_interest[str_sub(geo, 1, 2)])) %>%
    select(geo, country, sex, age, date_from, n_deaths)
```
# Deaths (DESTATIS)

© Statistisches Bundesamt (Destatis), 2024

Vervielfältigung und Verbreitung, auch auszugsweise, mit Quellenangabe gestattet.

```{r deaths_DESTATIS}
  # Read two different files and two separate tabs in each file, one for each sex
  deaths_2000_2020_m <- read_excel("../Downloads/Population/Deaths_Germany_2000_2020.xlsx", sheet = "csv-12613-10", col_types = "text")
  deaths_2000_2020_f <- read_excel("../Downloads/Population/Deaths_Germany_2000_2020.xlsx", sheet = "csv-12613-11", col_types = "text")
  deaths_2021_2025_m <- read_excel("../Downloads/Population/Deaths_Germany_2021_2025.xlsx", sheet = "csv-12613-10", col_types = "text")
  deaths_2021_2025_f <- read_excel("../Downloads/Population/Deaths_Germany_2021_2025.xlsx", sheet = "csv-12613-11", col_types = "text")
  deaths_DESTATIS <- rbind(deaths_2000_2020_m, deaths_2000_2020_f, deaths_2021_2025_m, deaths_2021_2025_f) %>% select(!Statistik)

  # combine four tables, all with same columns, select 2000-2024 years
  deaths_DESTATIS <- deaths_DESTATIS  %>% distinct() %>%
    filter(Jahre %in% YEARS_MODEL, Alter != "Insgesamt") %>%
    mutate(age = str_replace(Alter, "85[+]", "85-99"), sex = ifelse(Geschlecht == "Weiblich", "F", "M")) %>%
    mutate(year_week = sprintf("%04d-W%02d-1", as.integer(Jahre), as.integer(Kalenderwoche)), date_from = ISOweek2date(year_week)) %>%
    left_join(., geo_info  %>% select(id_region, region, country), join_by("Gebiet" == "region")) %>%
    select(geo = id_region, country, sex, age, date_from, n_deaths = Sterbefaelle) %>%
    filter(!n_deaths %in% c("X", ".")) %>% mutate(n_deaths = as.integer(n_deaths))
```
# Deaths (ONS, Commissioned)

```{r deaths_ONS}
  # ONS uses region codes, NUTS requires the long version, conversion vector
  region_strings <- c("E12000001" = "North East (England)", "E12000002" = "North West (England)", "E12000003" = "Yorkshire and the Humber",
                      "E12000004" = "East Midlands (England)", "E12000005" = "West Midlands (England)",  "E12000006" = "East of England",
                      "E12000007" = "London", "E12000008" = "South East (England)", "E12000009" = "South West (England)", "W92000004" = "Wales")

  # deaths by week of occurrence, by region, by sex, and by five-year age group
  deaths_ONS <-
    read_xlsx("../Downloads/Population/Deaths_England_Wales_1981_2022.xlsx", sheet = "1", skip = 5) %>%
    rename("date_from" = "Week start date\r\n(Saturday)") %>% select(!starts_with("Week")) %>%
    mutate(sex = ifelse(Sex == "1", "M", "F")) %>% # as specified in Notes sheet inside the file
    pivot_longer(starts_with(c("E", "W")), names_to = "region_age", values_to = "n_deaths") %>%
    mutate(region_code = gsub("_.*", "", region_age), age_range = gsub(".*_", "", region_age)) %>%
    mutate(region = str_replace_all(region_code, region_strings)) %>%
    mutate(age = str_replace_all(age_range, c("<1" = "0-4", "95[+]" = "95-99", "01-04" = "0-4", "05-09" = "5-9"))) %>%
    left_join(., geo_info  %>% select(id_region, region, country), by = "region") %>%
    filter(date_from >= week_table$date_from[1] - 2) %>%
    group_by(geo = id_region, country, sex, age, date_from) %>% reframe(n_deaths = sum(n_deaths))
```
# Deaths (ONS, Provisional 2023)

```{r deaths_ONS_2023}
  deaths_ONS_2023 <- read_xlsx("../Downloads/Population/Deaths_England_Wales_2023_2024.xlsx", sheet = "Table_2", skip = 6) %>%
    select(region = starts_with("Area "), date_to = "Week ending", age = starts_with("Age "), sex = Sex, n_deaths = starts_with("Number")) %>%
    filter(region != "England, Wales and non-residents", region != "England", sex != "All people", age != "All ages") %>%
    mutate(sex = str_sub(sex, 1, 1), region = gsub("The", "the", ifelse(grepl("East$|West$|Midlands$", region), paste(region, "(England)"), region))) %>%
    left_join(., geo_info %>% select(id_region, region, country), by = "region") %>%
    mutate(date_from = as.Date(date_to, tryFormats = "%d %B %Y") - 6) %>%
    select(geo = id_region, country, sex, age, date_from, n_deaths) %>%
    mutate(age = str_replace_all(age, c(" to " = "-", "Under 1" = "0-4", "1-4" = "0-4", " and over" = "-99"))) %>%
    group_by(geo, country, sex, age, date_from) %>% reframe(n_deaths = sum(n_deaths))
```
# Deaths (INSEE)

```{r deaths_INSEE}
  # read all annual and monthly death record files
  file_names <- list.files(path = "../Downloads/Population/", pattern = "Deaths_France_", full.names = TRUE, recursive = FALSE)
  deaths_raw <- foreach (i = 1:length(file_names), .combine = "rbind", .packages = "tidyverse") %dopar% {
    load_csv(file_names[i]) %>% select(sex = sexe, datenaiss, datedeces, lieunaiss, lieudeces) %>%
      mutate(sex = ifelse(sex == 1, "M", "F")) %>%
      mutate(lieunaiss = as.character(lieunaiss), lieudeces = as.character(lieudeces)) %>% filter(lieudeces != "") %>%
      mutate(lieudeces = str_replace_all(lieudeces, c("2A" = "20", "2B" = "20"))) %>%
      mutate(datenaiss = as.Date(as.character(datenaiss), format = "%Y%m%d")) %>% filter(!is.na(datenaiss))  %>%
      mutate(datedeces = as.Date(as.character(datedeces), format = "%Y%m%d")) %>% filter(!is.na(datedeces))  %>%
      mutate(age_at_death = as.integer(difftime(datedeces, datenaiss, units = "days")) %/% 365.25) %>% filter(age_at_death %in% 0:120) %>%
      mutate(age_at_death = pmin(age_at_death, 99)) %>%
      mutate(zip = as.integer(lieudeces) %/% 1000) %>% filter(zip > 0, zip < 96)
  }

  # clean up records, remove full duplicates (noting that distinct is much faster than unique)
  deaths_unique <- distinct(deaths_raw) %>% select(sex, age_at_death, datedeces, zip) %>% mutate(zip = as.character(zip))

  # exclude records for deaths that occurred in prior years, retain only deaths from FIRST_WEEK to LAST_WEEK
  deaths_INSEE <- deaths_unique %>%
    filter(datedeces >= min(week_table$date_from), datedeces <= max(week_table$date_to)) %>%
    left_join(., zip_codes_fr, by = "zip") %>%
    left_join(., age_5y_standard, join_by("age_at_death" >= "age_from", "age_at_death" <= "age_to")) %>%
    left_join(., week_table, join_by("datedeces" >= "date_from", "datedeces" <= "date_to")) %>%
    group_by(geo = id_region, sex, age, date_from) %>% reframe(n_deaths = n()) %>%
    complete(geo, sex, age, date_from, fill = list(n_deaths = 0)) %>% mutate(country = "France")
```
# Deaths: Aggregate

```{r deaths}
  # combine deaths into one tidy table, combine all 85+ groups into one age category, aggregate to 4 categories, append Germany
  deaths_5y <- rbind(deaths_eurostat, deaths_ONS, deaths_ONS_2023, deaths_INSEE) %>%
    mutate(age = str_replace_all(age, c("85-89" = "85-99", "90-94" = "85-99", "95-99" = "85-99", "90-99" = "85-99"))) %>%
    group_by(geo, country, sex, age, date_from) %>% reframe(n_deaths = sum(n_deaths))
  deaths_4cat <- left_join(deaths_5y, age_aggregate, by = "age") %>%
    group_by(geo, country, sex, age = age_cat, date_from) %>% reframe(n_deaths = sum(n_deaths)) %>%
    rbind(., deaths_DESTATIS)

  # clean up
  print(sprintf("Deaths.Rdata (is.na = %d)", sum(is.na(deaths_5y)) + sum(is.na(deaths_4cat))))
  rm(list = setdiff(ls(pattern = "deaths"), c("deaths_4cat", "deaths_5y"))); stop_gc()
```
# Populations: 1km x 1km grid, accumulate onto 0.1 x 0.1 degree grid (inside regions)

© Eurostat, 1995 - today

```{r population_distribution}
  # read file with shapes and population density at 1km by 1km resolution, convert to longitude/latitude
  population_density <- read_sf("../Downloads/Geography/JRC_POPULATION_2018.shp") %>%
    filter(CNTR_ID %in% names(countries_of_interest)) %>%
    st_transform(crs = 4326) %>% select(geometry, pop = TOT_P_2018)

  # compute centroid for each polygon (1km by 1km)
  centroids <- data.frame(st_coordinates(st_centroid(population_density$geometry)))
  population_density <- population_density %>% mutate(long = centroids$X, lat = centroids$Y) %>% select(!geometry)

  # find region that each populated node (1km x 1km grid) falls within
  st_p <- st_as_sf(x = population_density, coords = c("long", "lat"), crs = 4326)
  w_in <- map_int(st_within(st_p, geo_info$geometry), ~ifelse(length(.x) > 0, .x[1], NA))
  populated_grid <- population_density %>% mutate(region = geo_info$id_region[w_in]) %>% drop_na() %>%
    mutate(long = 0.10 * floor(10.0 * long) + 0.05, lat = 0.10 * floor(10.0 * lat) + 0.05) %>%
    group_by(geo = region, long, lat) %>% reframe(pop = sum(pop))

  # plot populated grid for visual check
  plot_pdf_png("Figure_X2", aspect_ratio = 1.0,
    populated_grid %>%
    group_by(long, lat) %>% reframe(pop = pmin(pmax(log10(sum(pop)), 2.5), 5.5)) %>%
    mutate(long_min = long - 0.05, long_max = long + 0.05, lat_min = lat - 0.05, lat_max = lat + 0.05) %>%
    ggplot(aes(xmin = long_min, xmax = long_max, ymin = lat_min, ymax = lat_max, fill = pop)) +
      geom_sf(data = geo_info$geometry, inherit.aes = FALSE, aes(), linewidth = 0.1, color = "#00007F", fill = "#00007F") +
      geom_rect() +
      labs(fill = "Population",
           y = "© Eurostat, EFGS, for the populations density grid", x = "© EuroGeographics for the administrative boundaries") +
      scale_fill_gradient(low = "#00007F", high = "#FFFF7F", breaks = 3:6, labels = ~sprintf("%d", 10^(3:6)), limits = c(2.5, 6.0)) +
      geom_sf(data = geo_info$geometry, inherit.aes = FALSE, aes(), linewidth = 0.2, color = "white", fill = NA) +
      std_theme())
  print("Figure_X2: Population 2018 on (0.1 ° x 0.1 °) Grid")

  # clean up memory (make room for temperature data)
  rm(list = ls(pattern = "population_density|centroids|st_p|w_in")); stop_gc()
```
# Daily Mean Temperatures

Acknowledgment: We acknowledge the E-OBS dataset from the EU-FP6 project UERRA (https://www.uerra.eu) and the Copernicus Climate Change Service, and the data providers in the ECA&D project (https://www.ecad.eu)

Citation: Cornes, R., G. van der Schrier, E.J.M. van den Besselaar, and P.D. Jones. 2018: An Ensemble Version of the E-OBS Temperature and Precipitation Datasets, J. Geophys. Res. Atmos., 123. doi:10.1029/2017JD028200

```{r daily_mean_temperature_eobs}
  date_from <- min(week_table$date_from) - LAG_MAX - 2 # ONS week starts on Saturday prior to Monday of ISO week

  # read temperature grid file for Europe (ensemble mean, all longitudes, all latitudes, since 1950-01-01)
  nc_file  <- nc_open("../Downloads/Temperature/tg_ens_mean_0.1deg_reg_v31.0e.nc")
  long     <- 0.10 * floor(10.0 * ncvar_get(nc_file, "longitude")) + 0.05 # longitude [°] -> center
  lat      <- 0.10 * floor(10.0 * ncvar_get(nc_file, "latitude"))  + 0.05 # latitude [°]  -> center
  idx_date <- as.integer(date_from - as.Date("1950-01-01")) + 1
  date_nc  <- as.Date("1950-01-01") + ncvar_get(nc_file, "time", start = idx_date, count = -1)

  # block read all temperatures at once (30 seconds, avoids 4.5 hours of poking in the file)
  tmp <- ncvar_get(nc_file, "tg", start = c(1, 1, idx_date), count = c(-1, -1, -1), raw_datavals = TRUE)
  tmpc_scale_factor <- ncatt_get(nc_file, "tg", "scale_factor")$value
  tmpc_fill_value   <- ncatt_get(nc_file, "tg", "_FillValue")$value
  tmpc_missing      <- tmpc_fill_value * tmpc_scale_factor
  nc_close(nc_file)

  # efficiently determine index (in temperature grid) for all elements of populations grid
  long_lookup <- data.frame(long, long_index = 1:length(long))
  lat_lookup  <- data.frame(lat,  lat_index  = 1:length(lat))
  populated_grid_with_lookup <- left_join(left_join(populated_grid, long_lookup, by = "long"), lat_lookup, by = "lat")

  # loop in parallel over regions, compute population_weighted mean temperature
  regions <- unique(populated_grid_with_lookup$geo)
  tmpc_mean <- foreach (i = 1:length(regions), .combine = "cbind", .packages = "tidyverse") %do% {
    grid_region <- populated_grid_with_lookup %>% filter(geo == regions[i])
    sum_temp <- rep(0.0, dim(tmp)[3])
    sum_pop  <- rep(0.0, dim(tmp)[3])
    for (j in 1:nrow(grid_region)) {
      idx_long <- grid_region$long_index[j]
      idx_lat  <- grid_region$lat_index[j]
      pop      <- grid_region$pop[j]
      tmpc_point <- tmpc_scale_factor * as.vector(tmp[idx_long,idx_lat,])
      sum_temp   <- sum_temp + ifelse(tmpc_point > tmpc_missing, pop * tmpc_point, 0.0)
      sum_pop    <- sum_pop  + ifelse(tmpc_point > tmpc_missing, pop,              0.0)
    }
    tmpc_mean <- data.frame(tmp = round(sum_temp / sum_pop, 1))
    names(tmpc_mean) <- grid_region$geo[1]
    tmpc_mean
  }

  # convert to tidy table
  temperatures <- cbind(date_nc, tmpc_mean) %>% pivot_longer(!date_nc, names_to = "geo", values_to = "tmp") %>% rename("date" = "date_nc")

  # compute all lagged temperatures, adding average over increasing number of prior days
  temperatures_daily_lagged = expand.grid(lag = 0:LAG_MAX, date_0 = date_nc, geo = unique(geo_info$id_region)) %>%
    mutate(date = date_0 - lag) %>%
    left_join(., temperatures, by = c("geo", "date")) %>%
    select(!date) %>% rename("date" = "date_0") %>%
    pivot_wider(values_from = tmp, names_from = lag, names_prefix = "tmpc_lag_") %>%
    filter(complete.cases(.)) %>%
    mutate(tmpc_lag_0_3 = round((tmpc_lag_0 + tmpc_lag_1 + tmpc_lag_2 + tmpc_lag_3) * 0.25, 1)) %>%
    select(geo, date, starts_with("tmpc_lag"))

  # compute all lagged temperatures for all days-of-the-week for all weeks
  temperatures_weekly_lagged <- expand.grid(geo = unique(geo_info$id_region), date_from = unique(deaths_4cat$date_from), day_of_week = 0:6) %>%
    mutate(date = date_from + day_of_week) %>%
    left_join(., temperatures_daily_lagged, by = c("geo", "date")) %>%
    filter(complete.cases(.)) %>%
    select(!date) %>%
    pivot_longer(starts_with("tmp"), names_to = "lag", values_to = "tmp") %>%
    mutate(variable = sprintf("%s_dow_%s", lag, day_of_week)) %>% select(geo, date_from, variable, tmp) %>%
    pivot_wider(values_from = tmp, names_from = variable)

  # clean up
  print(sprintf("Temperatures.Rdata (is.na = %d)", sum(is.na(temperatures_daily_lagged)) + sum(is.na(temperatures_weekly_lagged))))
  rm(nc_file, tmp); rm(list = setdiff(ls(pattern = "temperature"), c("temperatures_daily_lagged", "temperatures_weekly_lagged"))); stop_gc()

  # count consecutive number of days > 25 °C by region using run length encoding (rle)
  consecutive_days_25 <- temperatures_daily_lagged %>%
    arrange(geo, date) %>%
    mutate(warm = tmpc_lag_0 >= 25.0) %>%
    group_by(geo) %>%
    reframe(length = rle(warm)$lengths, values = rle(warm)$values) %>%
    filter(values == TRUE, length >= 3) %>%  # at least three consecutive days
    group_by(geo, length) %>%
    reframe(n = n()) %>%
    filter(length <= 21) %>%
    left_join(., geo_info %>% select(id_region, country), join_by("geo" == "id_region")) %>%
    group_by(country, length) %>% reframe(n = sum(n))

  plot_pdf_png("Figure_X3", aspect_ratio = 0.6,
    consecutive_days_25 %>%
    ggplot(aes(x = length, y = n, group_by = country, color = country, label = country)) +
      geom_point(size = 3.0) + geom_line(linewidth = 1.0) +
      scale_x_continuous(breaks = c(3, 7, 14, 21), trans = "log") +
      scale_color_manual(values = safe_colorblind_palette) +
      labs(y = "Total Number of Warm Stretches", x = "Consecutive Days >= 25 °C Mean Temperature") +
      std_theme() + theme(legend.position = "top", legend.title = element_blank()))
  print(sprintf("Figure_X3: Hot Stretches by Region (%s to %s)", min(temperatures_daily_lagged$date), max(temperatures_daily_lagged$date)))
```
# Temperature Plots

```{r temperature_plots}
  # create example plots for heat waves of 2003, 2019, and 2023
  plot_pdf_png("Figure_S4", aspect_ratio = 0.5,
    temperatures_daily_lagged %>%
    filter(date %in% c("2003-08-12", "2019-07-25", "2023-08-24")) %>%
    pivot_longer(starts_with("tmp"), names_to = "lag", values_to = "tmp") %>%
    filter(lag == "tmpc_lag_0_3") %>%
    mutate(lag = str_replace(lag, "tmpc_lag_", "")) %>%
    separate_wider_delim(lag, names = c("lmin", "lmax"), delim = "_") %>%
    mutate(cat = sprintf("%s - %s", date - as.integer(lmax), date - as.integer(lmin))) %>%
    left_join(., geo_info, join_by("geo" == "id_region")) %>% st_as_sf() %>%
    ggplot() +
      geom_sf(aes(fill = tmp)) +
      labs(fill = "T [°C]", x = "© EuroGeographics for the administrative boundaries, © E-OBS for the temperature data") +
      theme(legend.position = "right") +
      scale_x_continuous(breaks = seq(-10, 10, 10)) + scale_y_continuous(breaks = seq( 40, 50, 10)) +
      scale_fill_gradientn(colors = safe_heatmap_palette, breaks = seq(15, 30, 5), limits = c(12.0, 33.0)) +
      geom_sf(inherit.aes = FALSE, aes(), linewidth = 0.05, color = "black", fill = NA) +
      std_theme() + facet_wrap(~cat, nrow = 1, dir = "h"))
  print("Figure_S4: Average Temperatures", fill = "T [°C]")
```
# Outcome Plots: Deaths (Absolute, Standardized)

```{r deaths_plots}
  # EU-27 + EFTA Standard Population 2013, with 0-4 years combined into one group and 85+ years combined into one group, plus 4 coarse age categories
  population_eu_5y <- data.frame(age = paste(seq(0, 85, 5), c(seq(4, 84, 5), 99), sep = "-"),
                                 n_pop_eu27 = 100 * c(50, 55, 55, 55, 60, 60, 65, 70, 70, 70, 70, 65, 60, 55, 50, 40, 25, 25))
  population_eu_4cat <- left_join(population_eu_5y, age_aggregate, by = "age") %>% group_by(age = age_cat) %>% reframe(n_pop_eu27 = sum(n_pop_eu27))
  population_eu <- distinct(rbind(population_eu_5y, population_eu_4cat))

  # calculate total deaths for each country and for a standard population in each country
  deaths_total <- left_join(deaths_4cat %>% mutate(year = year(date_from)), population_4cat, by = c("geo", "country", "year", "sex", "age")) %>%
    group_by(country, year, age, date_from) %>% reframe(n_deaths = sum(n_deaths), n_pop = sum(n_pop)) %>%
    left_join(., population_eu, by = "age") %>% mutate(n_deaths_std = n_deaths * n_pop_eu27 / n_pop) %>%
    group_by(country, year, date_from) %>% reframe(n_deaths = sum(n_deaths), n_deaths_std = sum(n_deaths_std))

  # deaths (observed)
  plot_pdf_png("Figure_X4", aspect_ratio = 1.2,
    deaths_total %>% filter(year %in% YEARS_MODEL, country != "Luxembourg") %>%
    mutate(panel = sprintf("%d-%d", year - (year - min(YEARS_MODEL)) %% 8, year - (year - min(YEARS_MODEL)) %% 8 + 7)) %>%
    ggplot(aes(x = date_from, y = n_deaths, group_by = country, color = country)) +
      geom_line(linewidth = 0.5) +
      scale_x_continuous(breaks = YEAR_BREAKS, labels = YEAR_LABELS) +
      labs(color = "", x = "", y = "Weekly Deaths") +
      scale_color_manual(values = safe_colorblind_palette) +
      std_theme() + theme(legend.position = "top", axis.ticks.x=element_blank()) +
      guides(color = guide_legend(nrow = 2, byrow = FALSE)) + facet_wrap(~panel, ncol = 1, scales = "free_x"))
  print("Figure_X4: Deaths (Observed)")

  # deaths (standardized, with mean over all weekly deaths removed by country)
  plot_pdf_png("Figure_X5", aspect_ratio = 1.2,
    deaths_total %>% filter(year %in% YEARS_MODEL, country != "Luxembourg") %>%
    group_by(country) %>% mutate(n_deaths_std = n_deaths_std - mean(n_deaths_std)) %>% ungroup() %>%
    mutate(panel = sprintf("%d-%d", year - (year - min(YEARS_MODEL)) %% 8, year - (year - min(YEARS_MODEL)) %% 8 + 7)) %>%
    ggplot(aes(x = date_from, y = n_deaths_std, group_by = country, color = country)) +
      geom_line(linewidth = 0.5) +
      scale_x_continuous(breaks = YEAR_BREAKS, labels = YEAR_LABELS) +
      labs(color = "", x = "", y = "Weekly Mortality Rate - Mean(Weekly Mortality Rate)") +
      scale_color_manual(values = safe_colorblind_palette) +
      std_theme() + theme(legend.position = "top", axis.ticks.x=element_blank()) +
      guides(color = guide_legend(nrow = 2, byrow = FALSE)) + facet_wrap(~panel, ncol = 1, scales = "free_x"))
  print("Figure_X5: Deaths (EU27 Standard Population)")
```
# Exposure Response (Raw)

Exposure response is shown by country, as the sum over incremental deaths across the regions, by temperature bracket (integer degree +/- 0.5 degrees), for pre-pandemic years, for summer weeks.

```{r exposure_response_plot}
  # define temperature exposure for a week as the maximum over the 1-to-3 day lagged average temperatures, over the days of the week
  tmpc_exposure <- temperatures_weekly_lagged %>%
    mutate(tmpc_max_lag_0_3 = round(pmax(tmpc_lag_0_3_dow_0, tmpc_lag_0_3_dow_1, tmpc_lag_0_3_dow_2, tmpc_lag_0_3_dow_3,
                                         tmpc_lag_0_3_dow_4, tmpc_lag_0_3_dow_5, tmpc_lag_0_3_dow_6), 0)) %>%
    select(geo, date_from, tmpc_max_lag_0_3)

  # retrieve deaths per country, append population and exposure data, bucket exposure by degree, sum exposed population, compute death rate
  incremental_death_rate_by_country_exposure_by_region <-
    left_join(deaths_4cat %>% mutate(year = year(date_from)), population_4cat, by = c("geo", "country", "year", "sex", "age")) %>%
    filter(date_from >= min(week_table$date_from), year < min(COVID_YEARS)) %>%
    group_by(geo, year, sex, age) %>% mutate(n_deaths = n_deaths - mean(n_deaths)) %>% ungroup() %>%
    left_join(., tmpc_exposure, by = c("geo", "date_from")) %>%
    mutate(decade = sprintf("%d-%d", 10 * (year %/% 10), 10 * (year %/% 10) + 9)) %>%
    mutate(week = gsub("^.*W", "", ISOweek(date_from + 2))) %>%
    filter(week >= FIRST_SUMMER_WEEK, week <= LAST_SUMMER_WEEK) %>%
    mutate(country = ifelse(country %in% c("England", "Wales"), "England.Wales", country)) %>%
    group_by(country, decade, age, tmpc_max_lag_0_3) %>% reframe(r_deaths = 100000.0 * sum(n_deaths) / sum(n_pop), n_pop = sum(n_pop))

  plot_pdf_png("Figure_1", aspect_ratio = 0.9,
    incremental_death_rate_by_country_exposure_by_region %>% filter(tmpc_max_lag_0_3 >= 5.0) %>%
    ggplot(aes(x = tmpc_max_lag_0_3, y = r_deaths, group_by = country, color = country, weight = n_pop)) +
      geom_smooth(aes(fill = country), formula = y ~ x, method = "loess", span = 0.8, se = TRUE, alpha = 0.2) +
      labs(color = "", fill = "",
           x = "Exposure: Mean Temperature over prior 0:3 Days, Maximum over 7 Days of Week",
           y = "Weekly Rate of Incremental Deaths in Summer [1/100k]\nvs. Region-Year-Sex-Age Mean, All Regions") +
      scale_x_continuous(breaks = seq(10, 30, 10), labels = ~sprintf("%d °C", .x)) +
      scale_fill_manual(values = safe_colorblind_palette) +
      scale_color_manual(values = safe_colorblind_palette) +
      guides(fill = guide_legend(nrow = 2, byrow = FALSE)) +
      std_theme() + theme(legend.position = "top") +
      facet_grid2(vars(decade), vars(age), scales = "free_y", axes = "y", independent = "y") +
      facetted_pos_scales(y = list(age == "0-64"  ~ scale_y_continuous(limits = c(  -4,  10), breaks = seq(  0,  10,  5)),
                                   age == "65-74" ~ scale_y_continuous(limits = c( -12,  30), breaks = seq(-10,  30, 10)),
                                   age == "75-84" ~ scale_y_continuous(limits = c( -36,  90), breaks = seq(-30,  90, 30)),
                                   age == "85-99" ~ scale_y_continuous(limits = c(-108, 270), breaks = seq(-90, 270, 90)))))
  print("Figure_1: Raw Exposure Response Curves (Summer), Incremental Deaths")

  plot_pdf_png("Figure_2", aspect_ratio = 0.7,
    incremental_death_rate_by_country_exposure_by_region %>% filter(tmpc_max_lag_0_3 >= 5.0) %>%
    filter(age %in% c("75-84", "85-99")) %>%
    ggplot(aes(x = tmpc_max_lag_0_3, y = r_deaths, group_by = interaction(age, decade), color = age, weight = n_pop)) +
      geom_smooth(aes(fill = age, color = age, linetype = decade), formula = y ~ x, method = "loess", span = 0.8, se = TRUE, alpha = 0.2) +
      labs(color = "", fill = "", linetype = "",
           x = "Exposure: Mean Temperature over prior 0:3 Days, Maximum over 7 Days of Week",
           y = "Weekly Rate of Incremental Deaths in Summer [1/100k]\nvs. Region-Year-Sex-Age Mean, All Regions") +
      scale_x_continuous(breaks = seq(10, 30, 10), labels = ~sprintf("%d °C", .x)) +
      scale_fill_manual(values = safe_colorblind_palette[c(4,2)]) +
      scale_color_manual(values = safe_colorblind_palette[c(4,2)]) +
      scale_linetype_manual(values = c("11", "solid")) +
      guides(fill = guide_legend(nrow = 1, byrow = FALSE), linetype = guide_legend(nrow = 1, byrow = FALSE, override.aes = list(color = "black", fill = "#BFBFBF"))) +
      std_theme() + theme(legend.position = "top") + facet_wrap(~country, nrow = 2))
  print("Figure_2: Raw Exposure Response Curves (Summer), Incremental Deaths, 74-84 and 85+ Years")
```
# Combine Required Data

Merge tables of deaths and populations, combine England and Wales into England.Wales for the main analysis, append (lagged) temperature exposures, filter on summer weeks.

```{r combine_geography_deaths_temperatures}
  # combine deaths and populations, adding week of year(Mon after Sat week start for UK, Wed for rest of Europe), select summer weeks only
  df_summer <- left_join(deaths_4cat %>% mutate(year = year(date_from)), population_4cat, by = c("geo", "country", "year", "sex", "age")) %>%
    filter(date_from >= min(week_table$date_from)) %>%
    mutate(week = gsub("^.*W", "", ISOweek(date_from + 2))) %>%
    left_join(., temperatures_weekly_lagged, by = c("geo", "date_from")) %>%
    mutate(country = ifelse(country %in% c("England", "Wales"), "England.Wales", country)) %>%
    arrange(country, geo, sex) %>%
    mutate(across(c(geo, country, sex), ~fct_inorder(.x))) %>%
    mutate(across(c(date_from, year, week, n_deaths, n_pop), ~as.integer(.x))) %>%
    filter(week >= FIRST_SUMMER_WEEK, week <= LAST_SUMMER_WEEK) %>%
    filter(date_from >= min(week_table$date_from), date_from <= max(week_table$date_from))
  save(df_summer, file = "../Processed/DeathsPopTemp.Rdata", compress = "xz")
```
# Done

```{r done}
  print(proc.time() - start_time); rstudioapi::versionInfo(); sessionInfo()
```